{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJP6VCHVMKYm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, model, optimizer, loss_fn, t_u_train, t_u_val, t_c_train, t_c_val):\n",
        "  start_time = time.time()\n",
        "\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    t_p_train = model(t_u_train)\n",
        "    loss_train = loss_fn(t_p_train, t_c_train)\n",
        "\n",
        "    t_p_val = model(t_u_val)\n",
        "    loss_val = loss_fn(t_p_val, t_c_val)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0 or epoch <= 3:\n",
        "      print(f'Epoch={epoch}, training loss={loss_train.item():e}, validation loss={loss_val.item():e}')\n",
        "\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(f\"Training completed in {elapsed_time:.2f} seconds.\")"
      ],
      "metadata": {
        "id": "sZLWsEtoNbqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/HamedTabkhi/Intro-to-ML/refs/heads/main/Dataset/Housing.csv'\n",
        "dataset = pd.DataFrame(pd.read_csv(url))\n",
        "\n",
        "x = dataset.drop(columns=['price','furnishingstatus'])\n",
        "varlist = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
        "\n",
        "def binary_map(x):\n",
        "    return x.map({'yes': 1, 'no': 0})\n",
        "\n",
        "x[varlist] = x[varlist].apply(binary_map)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x = pd.DataFrame(scaler.fit_transform(x)).values\n",
        "\n",
        "y = dataset['price'].values\n",
        "\n",
        "# np.random.seed(0)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, test_size = 0.2, random_state = 100)\n",
        "\n",
        "t_u_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "t_u_val = torch.tensor(x_test, dtype=torch.float32)\n",
        "t_c_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "t_c_val = torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "FMKiGE6eSuwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(11,8),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(8,1)\n",
        ")\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 3000,\n",
        "    model = model,\n",
        "    optimizer = optimizer,\n",
        "    loss_fn = nn.MSELoss(),\n",
        "    t_u_train = t_u_train,\n",
        "    t_u_val = t_u_val,\n",
        "    t_c_train = t_c_train,\n",
        "    t_c_val = t_c_val\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afIWm0DsSQCq",
        "outputId": "4cbd3188-ad17-44cf-b243-0e88875c1062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([436])) that is different to the input size (torch.Size([436, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([109])) that is different to the input size (torch.Size([109, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch=1, training loss=2.647759e+13, validation loss=2.515876e+13\n",
            "Epoch=2, training loss=2.541248e+13, validation loss=2.412424e+13\n",
            "Epoch=3, training loss=1.824704e+13, validation loss=1.719312e+13\n",
            "Epoch=500, training loss=3.484728e+12, validation loss=3.552006e+12\n",
            "Epoch=1000, training loss=3.483451e+12, validation loss=3.551835e+12\n",
            "Epoch=1500, training loss=3.482468e+12, validation loss=3.551686e+12\n",
            "Epoch=2000, training loss=3.481705e+12, validation loss=3.551557e+12\n",
            "Epoch=2500, training loss=3.481108e+12, validation loss=3.551442e+12\n",
            "Epoch=3000, training loss=3.480638e+12, validation loss=3.551342e+12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part B"
      ],
      "metadata": {
        "id": "geMPHnAFVwBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(11,8),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(8,8),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(8,8),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(8,1)\n",
        ")\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 3000,\n",
        "    model = model,\n",
        "    optimizer = optimizer,\n",
        "    loss_fn = nn.MSELoss(),\n",
        "    t_u_train = t_u_train,\n",
        "    t_u_val = t_u_val,\n",
        "    t_c_train = t_c_train,\n",
        "    t_c_val = t_c_val\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1fR4SVmVvbf",
        "outputId": "bf880da2-aee4-4a63-939c-d6a5abd79b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch=1, training loss=2.647760e+13, validation loss=2.515876e+13\n",
            "Epoch=2, training loss=2.543313e+13, validation loss=2.414624e+13\n",
            "Epoch=3, training loss=1.824082e+13, validation loss=1.719852e+13\n",
            "Epoch=500, training loss=3.478581e+12, validation loss=3.550506e+12\n",
            "Epoch=1000, training loss=3.478581e+12, validation loss=3.550506e+12\n",
            "Epoch=1500, training loss=3.478581e+12, validation loss=3.550506e+12\n",
            "Epoch=2000, training loss=3.478581e+12, validation loss=3.550506e+12\n",
            "Epoch=2500, training loss=3.478581e+12, validation loss=3.550506e+12\n",
            "Epoch=3000, training loss=3.478581e+12, validation loss=3.550506e+12\n"
          ]
        }
      ]
    }
  ]
}